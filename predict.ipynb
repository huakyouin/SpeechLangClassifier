{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义无标签数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class UnlabeledMelFrequencyDataset(Dataset):\n",
    "    def __init__(self, data_dir, max_seq_length=300):\n",
    "        self.data = []\n",
    "        self.max_seq_length = max_seq_length\n",
    "        data_files = sorted(os.listdir(data_dir))  # 对文件列表进行排序\n",
    "        for file in data_files:\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            self.data.append(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_length_statistics(self):\n",
    "        lengths = [np.load(file).shape[0] for file in self.data]\n",
    "        max_length = max(lengths)\n",
    "        min_length = min(lengths)\n",
    "        avg_length = sum(lengths) / len(lengths)\n",
    "        percentile50_length = np.percentile(lengths, 50)\n",
    "        percentile25_length = np.percentile(lengths, 25)\n",
    "        percentile75_length = np.percentile(lengths, 75)\n",
    "        return {\n",
    "            \"max_length\": max_length,\n",
    "            \"min_length\": min_length,\n",
    "            \"avg_length\": avg_length,\n",
    "            \"percentile25_length\": percentile25_length,\n",
    "            \"percentile50_length\": percentile50_length,\n",
    "            \"percentile75_length\": percentile75_length\n",
    "        }\n",
    "    \n",
    "    def cut_left_useless(self,arr):\n",
    "        # 寻找第一列非空白的位置\n",
    "        non_negative_index = np.argmax(arr != -11.512925, axis=0)\n",
    "        # 去除左侧空白列的部分\n",
    "        trimmed_matrix = arr[ non_negative_index.min():]\n",
    "        return trimmed_matrix\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data[idx]\n",
    "        # 加载无标签梅尔频率数据\n",
    "        mel_data = np.load(file_path)  # 假设是.npy格式的文件\n",
    "        # 去除左侧空白\n",
    "        mel_data = self.cut_left_useless(mel_data)\n",
    "        # 对数据进行填充或截断\n",
    "        if mel_data.shape[0] < self.max_seq_length:\n",
    "            # 填充到最大长度\n",
    "            pad_length = self.max_seq_length - mel_data.shape[0]\n",
    "            mel_data = np.pad(mel_data, ((0, pad_length), (0, 0)), mode='constant', constant_values=0)\n",
    "        elif mel_data.shape[0] > self.max_seq_length:\n",
    "            # 截断到最大长度\n",
    "            mel_data = mel_data[:self.max_seq_length, :]\n",
    "        # 将梅尔频率特征转换为PyTorch张量并返回\n",
    "        return torch.tensor(mel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入预测数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test_data/test_0001.npy\n",
      "data/test_data/test_0002.npy\n",
      "data/test_data/test_0003.npy\n",
      "data/test_data/test_0004.npy\n",
      "data/test_data/test_0005.npy\n",
      "data/test_data/test_0006.npy\n",
      "data/test_data/test_0007.npy\n",
      "data/test_data/test_0008.npy\n",
      "data/test_data/test_0009.npy\n",
      "data/test_data/test_0010.npy\n",
      "data/test_data/test_0011.npy\n",
      "data/test_data/test_0012.npy\n",
      "data/test_data/test_0013.npy\n",
      "data/test_data/test_0014.npy\n",
      "data/test_data/test_0015.npy\n",
      "data/test_data/test_0016.npy\n",
      "data/test_data/test_0017.npy\n",
      "data/test_data/test_0018.npy\n",
      "data/test_data/test_0019.npy\n",
      "data/test_data/test_0020.npy\n",
      "{'max_length': 766, 'min_length': 40, 'avg_length': 190.651, 'percentile25_length': 72.0, 'percentile50_length': 199.0, 'percentile75_length': 288.0}\n"
     ]
    }
   ],
   "source": [
    "# 创建无标签数据集对象\n",
    "unlabeled_dataset = UnlabeledMelFrequencyDataset(data_dir='data/test_data', max_seq_length=300)\n",
    "# 创建数据加载器\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 确认按文件顺序排列\n",
    "# 打印出前 10 个文件路径\n",
    "for i in range(20):\n",
    "    print(unlabeled_dataset.data[i])\n",
    "\n",
    "print(unlabeled_dataset.get_length_statistics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完成预测任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models.network as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义模型结构\n",
    "model = models.MelCNN(unlabeled_dataset[0].shape,2).to(device)\n",
    "# model = models.MelTransformer().to(device)\n",
    "# 加载已保存的模型参数\n",
    "model.load_state_dict(torch.load('saved_models/model_cnn_v5.pth'))\n",
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = []\n",
    "for inputs in unlabeled_loader:\n",
    "    inputs = inputs.to(device)  # 将输入数据移动到设备上\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)  # 获取预测结果\n",
    "    predictions.extend(predicted.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               file  label\n",
      "0     test_0001.npy      1\n",
      "1     test_0002.npy      0\n",
      "2     test_0003.npy      0\n",
      "3     test_0004.npy      0\n",
      "4     test_0005.npy      1\n",
      "...             ...    ...\n",
      "1995  test_1996.npy      0\n",
      "1996  test_1997.npy      0\n",
      "1997  test_1998.npy      1\n",
      "1998  test_1999.npy      0\n",
      "1999  test_2000.npy      0\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "1084 916\n"
     ]
    }
   ],
   "source": [
    "# 检查预测结果\n",
    "import pandas as pd\n",
    "import os\n",
    "# 提取文件名\n",
    "file_names = [os.path.basename(file) for file in unlabeled_dataset.data]\n",
    "# 创建包含预测结果的DataFrame\n",
    "data = {'file': file_names, 'label': predictions}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "# 检查标签总数\n",
    "print(predictions.count(0),predictions.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将DataFrame写入Excel文件\n",
    "df.to_csv('23210980044.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VoiceLang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
